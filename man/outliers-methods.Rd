\name{outliers-methods}
\docType{methods}
\alias{outliers}
\alias{outliers-methods}
\alias{outliers,bigcforest-method}
\title{Compute Outlier Scores}
\description{
Compute outlier scores for each class of examples used to train a random forest. Outliers are defined as examples whose proximities to other examples in the same class are small.
}
\usage{
\S4method{outliers}{bigcforest}(forest, y, trace=0L)
}
\arguments{
  \item{forest}{
    A random forest of class \code{"\linkS4class{bigcforest}"}.
  }
  \item{y}{
    An integer or factor vector of response variables that was used in growing the forest. The data must not have changed, otherwise unexpected modelling results may occur.
  }
  \item{trace}{
    \code{0} for no verbose output. \code{1} to print verbose output. Default: \code{0}.
  }
}
\value{
  A numeric vector containing the outlier scores for each training example. Higher scores indicate greater dissimilarity from other training examples in the same class.
}
\section{Methods}{
\describe{

\item{\code{signature(forest = "bigcforest")}}{
Compute outlier scores for a classification random forest generated by \code{\link[bigrf]{bigrfc}}.
}
}}
\examples{
# Classify cars in the Cars93 data set by type (Compact, Large,
# Midsize, Small, Sporty, or Van).

# Load data.
data(Cars93, package="MASS")
x <- Cars93
y <- Cars93$Type

# Select variables with which to train model.
vars <- c(4:22)

# Run model, build 50 trees.
forest <- bigrfc(x, y, ntree=50L, varselect=vars)

# Calculate proximity matrix and scaling co-ordinates, and plot
# them.
prox <- proximities(forest, y)
scale <- scaling(prox)
plot(scale, col=as.integer(y) + 2, pch=as.integer(y) + 2)

# Calculate outlier scores, and circle the top 20\% percent of
# them in red.
outscores <- outliers(forest, y)
points(scale[outscores > quantile(outscores, probs=0.8), ],
    col=2, pch=1, cex=1.5)
}
\keyword{methods}
